{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93db4346-4c7c-42bb-aa1c-4368768afe24",
   "metadata": {},
   "source": [
    "# Part 2: EDA and Initial Analysis #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2388e9-0136-4b66-ae87-c8b6f8568c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e84ed-2dd8-42f5-bf0f-9b46f4761182",
   "metadata": {},
   "source": [
    "### Section I: Extracting Informative Fields from JSON ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ccc19-2fec-420a-81e2-b8b2470d61f8",
   "metadata": {},
   "source": [
    "I intend to include the following properties.  They seem most informative in distinguishing NFT types:\n",
    "- id\n",
    "- num_sales\n",
    "- collection -> name\n",
    "- creator -> address\n",
    "- traits\n",
    "- last_sale -> payment_token -> usd_price\n",
    "- last_sale -> transaction -> timestamp\n",
    "\n",
    "These may be of interest in the future, but their usefulness is questionable:\n",
    "- asset_contract -> description (May be useful with some NLP, but descriptions are pretty generic and mostly reference the collection name.)\n",
    "- background_color (Many are Null, and background color is unlikely to be a major factor.)\n",
    "- owner (Many of these are or Null, even though the NFTs have sold many times.  Is this a form of anonymity?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650c623-200f-4b42-acf1-10dd41c863c6",
   "metadata": {},
   "source": [
    "For some of these fields, I only want certain subfields.  However, it is possible for the fields to be Null, in which case I will assign Null to the subfields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f91a593-6b5e-4aa5-9951-df9846f56ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_creator_address(in_dict):\n",
    "    if in_dict == None:\n",
    "        return None\n",
    "    else:\n",
    "        return in_dict['address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2511e0-3c10-4d87-99de-5a159d702915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_saleprice(in_dict):\n",
    "    if in_dict == None:\n",
    "        return None\n",
    "    else:\n",
    "        return in_dict['payment_token']['usd_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f47d11-1012-4a3b-b67d-7b93947ae9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_saledate(in_dict):\n",
    "    if in_dict == None:\n",
    "        return None\n",
    "    else:\n",
    "        return in_dict['transaction']['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78b5d5-5c09-4a7c-8bcc-f3c0cf93282c",
   "metadata": {},
   "source": [
    "I'm now ready to extract the data from the stored files and store the information I need in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51eba9c2-b2d8-425b-a1a1-d17d647dbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df():\n",
    "    \n",
    "    request_passes = [[], [], []] # Each element in this list will contain all requests from one pass through the top 10,000 NFTs.\n",
    "    \n",
    "    for passnum in range(3):\n",
    "        \n",
    "        # In the filenames, passes were labled a, b, and c.\n",
    "        if passnum == 0:\n",
    "            whichpass = 'a'\n",
    "        elif passnum == 1:\n",
    "            whichpass = 'b'\n",
    "        else:\n",
    "            whichpass = 'c'\n",
    "        \n",
    "        # There were 200 requests in each pass.\n",
    "        for request in range(1, 201):\n",
    "            request_passes[passnum].append(json.load(open(f'./raw_data/request_{request}_{whichpass}', 'r')))\n",
    "            \n",
    "    # Fields to be initially extracted from dictionaries.\n",
    "    ids = [[], [], []]\n",
    "    num_sales = [[], [], []]\n",
    "    collection_name = [[], [], []]\n",
    "    collection_slug = [[], [], []]\n",
    "    creator = [[], [], []]\n",
    "    last_sale = [[], [], []]\n",
    "    traits = [[], [], []]\n",
    "    owner = [[], [], []] ##\n",
    "    \n",
    "    # Subfields that must be extracted using the functions defined above.\n",
    "    creator_address = [[], [], []]\n",
    "    last_sale_price = [[], [], []]\n",
    "    last_sale_date = [[], [], []]\n",
    "\n",
    "    # List that will hold the Dataframe for each pass.\n",
    "    df_list = [[], [], []]\n",
    "    \n",
    "    for passnum in range(3):\n",
    "\n",
    "        for request in request_passes[passnum]:\n",
    "            \n",
    "            for nft in request['assets']:\n",
    "                ids[passnum].append(nft['id'])\n",
    "                num_sales[passnum].append(nft['num_sales'])\n",
    "                collection_name[passnum].append(nft['collection']['name'])\n",
    "                collection_slug[passnum].append(nft['collection']['slug'])\n",
    "                creator[passnum].append(nft['creator'])\n",
    "                last_sale[passnum].append(nft['last_sale'])\n",
    "                traits[passnum].append(nft['traits'])\n",
    "                owner[passnum].append(nft['owner'])\n",
    "        \n",
    "        # Use functions defined above to extract subfields from fields tha have some None values.\n",
    "        creator_address[passnum] = [get_creator_address(entry) for entry in creator[passnum]]\n",
    "        last_sale_price[passnum] = [get_last_saleprice(entry) for entry in last_sale[passnum]]\n",
    "        last_sale_date[passnum] = [get_last_saledate(entry) for entry in last_sale[passnum]]\n",
    "        \n",
    "        # Zip the features together in preparation for making the Dataframe.\n",
    "        features = zip(ids[passnum], num_sales[passnum], collection_name[passnum], collection_slug[passnum], creator_address[passnum],\n",
    "                       last_sale_price[passnum], last_sale_date[passnum],\n",
    "                       traits[passnum], owner[passnum])\n",
    "        \n",
    "        # Create the dataframe for the current pass.\n",
    "        df_list[passnum] = pd.DataFrame(features, columns=['asset_id', 'num_sales', 'collection_name', 'collection_slug', 'creator_address',\n",
    "                                                           'last_sale_price', 'last_sale_date', 'traits', 'owner'])\n",
    "    \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2faac0eb-b8f8-4d65-84db-1cfcc022b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = json_to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ccddd6-e2ba-47c0-885c-499743891502",
   "metadata": {},
   "source": [
    "### Section II: Cleaning and Initial EDA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2798a5d-b3d5-49d3-89d3-a8b2ceefa713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list[0]['collection_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0796118-db8d-4f2b-a246-2ca48edc60f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dodgers MLB Crypto      2295\n",
       "Rarible                 1156\n",
       "Hero                     812\n",
       "The Sandbox ASSETS       230\n",
       "Town Star                196\n",
       "                        ... \n",
       "Jamaican Bobsled NFT       1\n",
       "Greetings by Z             1\n",
       "Macchina di Lusso          1\n",
       "COACHK - CLUB              1\n",
       "Conscience Cards           1\n",
       "Name: collection_name, Length: 1325, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0]['collection_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649b74a-2c26-4547-a85f-3fca79d9110e",
   "metadata": {},
   "source": [
    "Some observations: why traits and owner are essentially useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991dbf9f-27df-4034-bacd-2491b9a7966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7bcccd4-afce-4308-8d2b-2ad0768af9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list[0]['traits'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc15531a-0a83-4624-a6ab-487cce3ec011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_types(traits):\n",
    "#     if traits == []:\n",
    "#         return None\n",
    "#     else:\n",
    "#         types = [trait['trait_type'] for trait in traits]\n",
    "#         return types\n",
    "    \n",
    "# df_list[0]['trait_types'] = df_list[0]['traits'].apply(get_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6333041-85c0-449a-ada4-6cc0543d62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list[0]['trait_types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a6167e-3f7e-42ea-9234-29b9faa4d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list[0].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545f8205-45ab-4492-9c26-adee6320767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       151609016\n",
       "1        44596334\n",
       "2        48159964\n",
       "3        76676445\n",
       "4        18781782\n",
       "          ...    \n",
       "5215     78597154\n",
       "5216     31629888\n",
       "5217     36068919\n",
       "5218     16813677\n",
       "5219     18332356\n",
       "Name: asset_id, Length: 5220, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0][df_list[0]['num_sales'] >= 20]['asset_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc53226-acef-4c4a-adf0-74431b6ce044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b823a-5e41-453a-b346-4c3a74daa57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661e4bb6-8472-4c63-9457-6bed43dbbeeb",
   "metadata": {},
   "source": [
    "How can the last sale be None when there are 15 sales?  Were they sold as part of a bundle, and if so, does that cause this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d104e5-af6d-4b94-80cc-c4a3f91f276f",
   "metadata": {},
   "source": [
    "Check things like:\n",
    "- Number of different collections\n",
    "- Distribution of num_sales\n",
    "- Distribution of sale prices and dates\n",
    "- Distributions among different collections.\n",
    "- Is there a 1-to-1 relationship between collection name and creator address?\n",
    "- Examine changes from one pass to the next, whether the most changes and odd behavior are at the bottom of the list, duplicates and apparent omissions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8423ef-c734-41dc-b674-851cdb0731ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for duplicates and let the user know if there are none.\n",
    "# if len(ids) == len(set(ids)):\n",
    "#     print('No duplicates found.')\n",
    "#     f = open('./raw_data/duplicates.txt', 'a')\n",
    "#     f.write(f'Unique IDs found: {len(set(ids))}')\n",
    "#     f.write('No duplicates!')\n",
    "#     f.close()\n",
    "\n",
    "# # If there are duplicates, make a list of them and save it in a file.\n",
    "# else:\n",
    "#     ids.sort() # Sort the ids to make it easy to check for duplicates.\n",
    "#     duplicate_ids = [ident for i, ident in enumerate(ids[:-1]) if ids[i] == ids[i+1]] # Create the list of duplicates.\n",
    "#     print(f'Duplicates found with the following IDs: {duplicate_ids}.')\n",
    "#     f = open('./raw_data/duplicates.txt', 'a')\n",
    "#     for ident in duplicate_ids:\n",
    "#         f.write(f'{ident}\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844c44c-cc40-4ecb-be98-8fae565ed95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e0660-ceaa-4419-bc45-3240ed20fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list[0][df_list[0]['num_sales'] >= 20]['collection_slug'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386e663-00fc-469c-bd4c-289f0cc48c7a",
   "metadata": {},
   "source": [
    "Join all the dataframes into one, which will be used to identify all unique collection slugs identified with any NFT having at least 20 sales at the time of data collection for any of the three passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4337d4f-bd22-4cd3-8374-91a3a8af6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37c382e-e76a-4b67-997e-708c51115177",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_collections = [slug for slug in df_full[df_full['num_sales'] >= 20]['collection_slug'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1329e6e8-ac56-4359-aa93-6b5a4f3cd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_collections_df = pd.DataFrame(top_collections, columns=['slug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "758ee8df-0378-4b44-9c16-4f5bb5d0c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_collections_df.to_csv('./top_collections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ffca1d-b2fe-4bf3-9b0a-18c0d620b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_collections_test = top_collections_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35949db9-fe30-4d2f-9f95-1beb59fd5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_collections_test.to_csv('./top_collections_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262c11c-531c-4d69-9098-94bdd67fd8c2",
   "metadata": {},
   "source": [
    "### Section III: Combining the Three Passes into One DataFrame ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a132a6e-3c44-4d6f-a9fd-41ce74b2574f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
